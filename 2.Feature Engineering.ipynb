{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6e239cd-83f9-46a3-93f5-54bc93ac6a37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /local_disk0/.ephemeral_nfs/envs/pythonEnv-834aeedc-770e-4601-b732-922fe6675585/lib/python3.9/site-packages (0.17.1)\nRequirement already satisfied: nltk>=3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-834aeedc-770e-4601-b732-922fe6675585/lib/python3.9/site-packages (from textblob) (3.8.1)\nRequirement already satisfied: tqdm in /local_disk0/.ephemeral_nfs/envs/pythonEnv-834aeedc-770e-4601-b732-922fe6675585/lib/python3.9/site-packages (from nltk>=3.1->textblob) (4.66.1)\nRequirement already satisfied: click in /databricks/python3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (8.0.4)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-834aeedc-770e-4601-b732-922fe6675585/lib/python3.9/site-packages (from nltk>=3.1->textblob) (2023.10.3)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.9/site-packages (from nltk>=3.1->textblob) (1.1.1)\nWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\nYou should consider upgrading via the '/local_disk0/.ephemeral_nfs/envs/pythonEnv-834aeedc-770e-4601-b732-922fe6675585/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "471ebc4e-3ad5-4bd1-a65e-c62d1670efb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=3473232305868530#setting/sparkui/1215-013039-uzkgmilc/driver-1110121286396476414\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=3473232305868530#setting/sparkui/1215-013039-uzkgmilc/driver-1110121286396476414\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[3]\") \\\n",
    "                            .appName('MyApplicationName') \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "499c00f7-ebe9-414f-bd74-911d254d87f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import boto3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe6e0c7-5a74-49c5-addb-423ec646ca5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "access_key = ''\n",
    "secret_key = ''\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key\n",
    "enconded_secret_key = secret_key.replace(\"/\", \"%2F\")\n",
    "aws_region = \"us-east-2\"\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + aws_region + \".amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb7b7472-ae24-4c87-99a6-35001c0186bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\n",
    "\n",
    "bucket_name = 'my-bigdata-project-sw/raw/'\n",
    "#file_name = 'cleaned_amazon_reviews_us_Personal_Care_Appliances_v1_00.tsv/'\n",
    "file_path = 's3://' + bucket_name + 'cleaned_spark_data_frame.parquet/*'\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"product_id\", StringType(), True),\n",
    "    StructField(\"product_parent\", IntegerType(), True),\n",
    "    StructField(\"product_title\", StringType(), True),\n",
    "    StructField(\"product_category\", StringType(), True),\n",
    "    StructField(\"star_rating\", StringType(), True),\n",
    "    StructField(\"helpful_votes\", IntegerType(), True),\n",
    "    StructField(\"total_votes\", IntegerType(), True),\n",
    "    StructField(\"verified_purchase\", StringType(), True),\n",
    "    StructField(\"review_headline\", StringType(), True),\n",
    "    StructField(\"review_body\", StringType(), True),\n",
    "    StructField(\"review_date\", DateType(), True),\n",
    "    StructField(\"clean_review_headline\", StringType(), True),\n",
    "    StructField(\"clean_review_body\", StringType(), True)\n",
    "])\n",
    "\n",
    "#sdf = spark.read.parquet(file_path)\n",
    "sdf = spark.read.schema(schema).parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2de80345-e4c6-4e4e-a81b-823703b42044",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------------+----------------+-----------+-------------+-----------+-----------------+--------------------+--------------------+-----------+---------------------+--------------------+\n|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|verified_purchase|     review_headline|         review_body|review_date|clean_review_headline|   clean_review_body|\n+----------+--------------+--------------------+----------------+-----------+-------------+-----------+-----------------+--------------------+--------------------+-----------+---------------------+--------------------+\n|0061091669|     998895209|Marilyn Monroe: T...|           Books|          5|            4|          5|                N|You MUST have thi...|Marilyn's fan or ...| 1996-12-09| You MUST have thi...|Marilyn's fan or ...|\n|1559723505|      61059309|The Highly Sensit...|           Books|          5|           12|         14|                N|Highlly Sensitive...|The Highly Sensit...| 1997-04-05| Highlly Sensitive...|The Highly Sensit...|\n|044651506X|     348227423|         Plum Island|           Books|          3|            0|          0|                N|  Not his best work.|I started this bo...| 1997-09-01|   Not his best work.|I started this bo...|\n|0671004107|     860650224|             Contact|           Books|          5|            1|          2|                N|A Compilation of ...|If you had one Ca...| 1997-09-17| A Compilation of ...|If you had one Ca...|\n|0671570439|     860650224|Contact (Movie Ti...|           Books|          4|            0|          0|                N|Forshadowing the ...|A radio signal mi...| 1997-10-14| Forshadowing the ...|A radio signal mi...|\n|0553573403|     268067011|A Game of Thrones...|           Books|          5|            0|          0|                N|   Outstanding book!|This is a wonderf...| 1997-11-10|    Outstanding book!|This is a wonderf...|\n|0425107469|      50861192|            Watchers|           Books|          5|            0|          0|                N|My favorite Dean ...|I just loved this...| 1997-11-13| My favorite Dean ...|I just loved this...|\n|0140013997|     888618380|My Family and Oth...|           Books|          4|            1|          2|                N|A lifetime favourite|My primary school...| 1997-11-19| A lifetime favourite|My primary school...|\n|0440133688|     515227012|The House of God:...|           Books|          3|            1|          2|                N|Interesting topic...|This book gives y...| 1997-12-03| Interesting topic...|This book gives y...|\n|1563523302|     826470409|The Millionaire N...|           Books|          5|            0|          0|                N|         Excellent!!|I'm the Head of a...| 1997-12-08|          Excellent!!|I'm the Head of a...|\n|0793518326|     977191911|The Beatles: Comp...|           Books|          5|            1|          1|                N|If you are a musi...|For the musician ...| 1998-01-10| If you are a musi...|For the musician ...|\n|0671004107|     860650224|             Contact|           Books|          5|            1|          2|                N|Loved the Movie? ...|I hardly give 10 ...| 1998-03-24| Loved the Movie? ...|I hardly give 10 ...|\n|0440214041|     859359548|   The Pelican Brief|           Books|          3|            0|          0|                N|             Hmmmmmm|I don't really kn...| 1998-04-03|              Hmmmmmm|I don't really kn...|\n|B000001FAK|     253828567|   The Turning Point|           Music|          5|            0|          0|                N|For John Mayall f...|The distinct lack...| 1998-04-28| For John Mayall f...|The distinct lack...|\n|0684874350|     698161422|Angela's Ashes (T...|           Books|          5|            0|          0|                N|This book is a mu...|Despite being a c...| 1998-05-08| This book is a mu...|Despite being a c...|\n|0784010188|     656011534|Terminator 2: Jud...|       Video DVD|          4|            0|          0|                N|Excellent transfe...|Excellent picture...| 1998-05-12| Excellent transfe...|Excellent picture...|\n|B0000028UK|      18577350|                 Vs.|           Music|          5|            0|          1|                N|         My favorite|No one can beat E...| 1998-05-16|          My favorite|No one can beat E...|\n|0345347951|     589013680|     Childhood's End|           Books|          5|            0|          3|                N|Most thought prov...|This book was ver...| 1998-06-13| Most thought prov...|This book was ver...|\n|B000002N3N|     262328741| The Memory of Trees|           Music|          5|            1|          1|                N|A new and varied ...|'Trees&quot; offe...| 1998-06-21| A new and varied ...|'Trees&quot; offe...|\n|B00000634L|     479934859|                Glee|           Music|          5|            0|          1|                N|Great disc to jus...|Music that you ca...| 1998-06-26| Great disc to jus...|Music that you ca...|\n+----------+--------------+--------------------+----------------+-----------+-------------+-----------+-----------------+--------------------+--------------------+-----------+---------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3dbfec3-8ad6-44b8-b2a3-fc7730675373",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "# Create a function to perform sentiment analysis on some text\n",
    "def sentiment_analysis(some_text):\n",
    "    sentiment = TextBlob(some_text).sentiment.polarity\n",
    "    return sentiment\n",
    "\n",
    "sentiment_analysis_udf = udf(sentiment_analysis, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cabccfc3-e988-4e9e-8dca-45505038a2e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Tokenize and process clean_review_body\n",
    "review_tokenizer = RegexTokenizer(inputCol=\"clean_review_body\", outputCol=\"clean_review_words\", pattern='\\\\w+', gaps=False)\n",
    "sdf = review_tokenizer.transform(sdf)\n",
    "\n",
    "review_stop_word_remover = StopWordsRemover(inputCol=\"clean_review_words\", outputCol=\"clean_review_filtered_words\")\n",
    "sdf = review_stop_word_remover.transform(sdf)\n",
    "\n",
    "review_hashing_tf = HashingTF(numFeatures=4096, inputCol=\"clean_review_filtered_words\", outputCol=\"clean_review_hash\")\n",
    "sdf = review_hashing_tf.transform(sdf)\n",
    "\n",
    "review_idf = IDF(inputCol=\"clean_review_hash\", outputCol=\"clean_review_features\", minDocFreq=1)\n",
    "sdf = review_idf.fit(sdf).transform(sdf)\n",
    "\n",
    "# Tokenize and process clean_review_headline\n",
    "headline_tokenizer = RegexTokenizer(inputCol=\"clean_review_headline\", outputCol=\"clean_headline_words\", pattern='\\\\w+', gaps=False)\n",
    "sdf = headline_tokenizer.transform(sdf)\n",
    "\n",
    "headline_stop_word_remover = StopWordsRemover(inputCol=\"clean_headline_words\", outputCol=\"clean_headline_filtered_words\")\n",
    "sdf = headline_stop_word_remover.transform(sdf)\n",
    "\n",
    "headline_hashing_tf = HashingTF(numFeatures=4096, inputCol=\"clean_headline_filtered_words\", outputCol=\"clean_headline_hash\")\n",
    "sdf = headline_hashing_tf.transform(sdf)\n",
    "\n",
    "headline_idf = IDF(inputCol=\"clean_headline_hash\", outputCol=\"clean_headline_features\", minDocFreq=1)\n",
    "sdf = headline_idf.fit(sdf).transform(sdf)\n",
    "\n",
    "# Apply sentiment analysis UDF\n",
    "sdf = sdf.withColumn(\"sentiment_score_review\", sentiment_analysis_udf(sdf['clean_review_body']))\n",
    "\n",
    "# Indexing and Encoding\n",
    "indexers = StringIndexer(inputCols=[\"product_id\", \"product_category\", \"verified_purchase\"], outputCols=[\"product_id_i\", \"product_category_i\", \"verified_purchase_i\"])\n",
    "encoder = OneHotEncoder(inputCols=[\"product_id_i\", \"product_category_i\", \"star_rating\", \"verified_purchase_i\"], outputCols=[\"product_id_v\", \"product_category_v\", \"star_rating_v\", \"verified_purchase_v\"], dropLast=False)\n",
    "assembler = VectorAssembler(inputCols=['star_rating_v', 'product_category_v', 'verified_purchase_v', \"clean_review_features\", \"clean_review_features\", \"clean_headline_features\", \"sentiment_score_review\"], outputCol=\"features\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[indexers, encoder, assembler])\n",
    "\n",
    "# Fit and transform the data\n",
    "final_sdf = pipeline.fit(sdf).transform(sdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e49a4fe-5894-43d4-b780-c79da06ae28b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#WRITE TO THE \"TRUSTED\" FOLDER IN AWS S3\n",
    "output_bucket_name = 'my-bigdata-project-sw/trusted/'\n",
    "output_file_name = \"featured_engineered_sdf\"\n",
    "\n",
    "output_file_path= 's3://' + output_bucket_name + output_file_name\n",
    "final_sdf.write.parquet(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aea23c90-a931-4749-977a-86492ab0ec97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1758843983095042,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "2.Feature Engineering",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
